{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# se detectan vehiculos sin reducir calidad de video y escogiendo un framerate, se almacenan las imagenes en \"detected_vehicles_images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video abierto. FPS = 29.99066484427621 | Tamaño: 1080 x 1920\n",
      "Fin del video.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "\n",
    "# Cargar el modelo YOLO v11 (usando \"yolo11n.pt\")\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Definir las clases de vehículos (según el mapeo COCO: car=2, motorcycle=3, bus=5, truck=7)\n",
    "vehicle_class_indices = [2, 3, 5, 7]\n",
    "\n",
    "# Crear carpeta para guardar las imágenes de vehículos detectados\n",
    "output_folder = \"detected_vehicles_images\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Definir la ruta del video a procesar y abrirlo\n",
    "video_path = 'videos/calle1.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error al abrir el video.\")\n",
    "    exit()\n",
    "\n",
    "# Obtener propiedades iniciales del video\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"Video abierto. FPS =\", fps, \"| Tamaño:\", height, \"x\", width)\n",
    "\n",
    "frame_count = 0\n",
    "vehicle_image_count = 0\n",
    "\n",
    "# Definir el intervalo de frames en el que se usará el modelo (por ejemplo, cada 10 frames)\n",
    "frame_interval = 10\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Fin del video.\")\n",
    "        break\n",
    "\n",
    "    # Corregir la orientación del frame aplicando una rotación\n",
    "    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "    \n",
    "    frame_count += 1\n",
    "\n",
    "    # Procesar solo el frame si se cumple el intervalo deseado\n",
    "    if frame_count % frame_interval != 0:\n",
    "        continue\n",
    "\n",
    "    # Usar el frame original sin reducción de calidad para realizar la detección\n",
    "    results = model(frame, imgsz=640, stream=False, verbose=False, conf=0.5, classes=vehicle_class_indices)\n",
    "    \n",
    "    if results and results[0].boxes is not None:\n",
    "        # Obtener las detecciones: [x1, y1, x2, y2, confidence, class]\n",
    "        dets = results[0].boxes.data.cpu().numpy() if hasattr(results[0].boxes.data, \"cpu\") else results[0].boxes.data\n",
    "        for det in dets:\n",
    "            x1, y1, x2, y2, conf, cls = det\n",
    "            cls = int(cls)\n",
    "            if cls in vehicle_class_indices:\n",
    "                # Asegurarse de que las coordenadas sean enteras y estén dentro de la imagen\n",
    "                x1_orig = max(int(x1), 0)\n",
    "                y1_orig = max(int(y1), 0)\n",
    "                x2_orig = min(int(x2), frame.shape[1])\n",
    "                y2_orig = min(int(y2), frame.shape[0])\n",
    "                \n",
    "                # Extraer la región de interés (ROI) del vehículo\n",
    "                roi = frame[y1_orig:y2_orig, x1_orig:x2_orig]\n",
    "                \n",
    "                # Generar un nombre único para la imagen usando la fecha y un contador\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "                filename = os.path.join(output_folder, f\"vehicle_{timestamp}_{vehicle_image_count}.png\")\n",
    "                cv2.imwrite(filename, roi)\n",
    "                vehicle_image_count += 1\n",
    "\n",
    "                # (Opcional) Dibujar un rectángulo en el frame original para visualizar la detección\n",
    "                cv2.rectangle(frame, (x1_orig, y1_orig), (x2_orig, y2_orig), (0, 255, 0), 4)\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementacion con deepsort_realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video abierto. FPS = 23.976023976023978 | Tamaño: 720 x 1280\n",
      "Fin del video.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# Cargar el modelo YOLO (en este ejemplo \"yolo11n.pt\")\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "# Clases de vehículos (COCO: car=2, motorcycle=3, bus=5, truck=7)\n",
    "vehicle_class_indices = [2, 3, 5, 7]\n",
    "\n",
    "# Inicializar DeepSORT\n",
    "tracker = DeepSort(max_age=30)\n",
    "\n",
    "# Configurar video de entrada\n",
    "video_path = 'videos/calle4.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error al abrir el video.\")\n",
    "    exit()\n",
    "\n",
    "# Propiedades del video\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"Video abierto. FPS =\", fps, \"| Tamaño:\", height, \"x\", width)\n",
    "\n",
    "# Configurar video de salida (recordar que se rota el frame, por lo que ancho y alto pueden intercambiarse)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output_tracked.mp4', fourcc, fps, (height, width))\n",
    "\n",
    "frame_count = 0\n",
    "frame_interval = 1\n",
    "\n",
    "def get_color(idx):\n",
    "    \"\"\"Genera un color único para cada ID (nota: se reinicia la semilla para consistencia).\"\"\"\n",
    "    np.random.seed(idx)\n",
    "    return tuple(np.random.randint(0, 255, 3).tolist())\n",
    "\n",
    "\n",
    "def get_color(idx):\n",
    "    \"\"\"Genera un color único para cada ID.\"\"\"\n",
    "    # Si idx es numérico en forma de string, conviértelo a entero.\n",
    "    try:\n",
    "        seed = int(idx)\n",
    "    except ValueError:\n",
    "        # Si no se puede convertir directamente, se puede usar hash y reducirlo.\n",
    "        seed = hash(idx) % (2**32)\n",
    "    np.random.seed(seed)\n",
    "    return tuple(np.random.randint(0, 255, 3).tolist())\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Fin del video.\")\n",
    "        break\n",
    "\n",
    "    # Rotar el frame para corregir la orientación\n",
    "    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "    frame_count += 1\n",
    "\n",
    "    # Procesar el frame según un intervalo (por ejemplo, cada 10 frames)\n",
    "    if frame_count % frame_interval != 0:\n",
    "        out.write(frame)\n",
    "        continue\n",
    "\n",
    "    # Realizar detección con YOLO en las clases de vehículos\n",
    "    results = model(frame, imgsz=640, stream=False, verbose=False, conf=0.5, classes=vehicle_class_indices)\n",
    "\n",
    "    detections_for_tracker = []\n",
    "    if results and results[0].boxes is not None:\n",
    "        # Extraer detecciones: [x1, y1, x2, y2, conf, cls]\n",
    "        dets = results[0].boxes.data.cpu().numpy() if hasattr(results[0].boxes.data, \"cpu\") else results[0].boxes.data\n",
    "        for det in dets:\n",
    "            x1, y1, x2, y2, conf, cls = det\n",
    "            # Convertir la caja a formato [x, y, ancho, alto]\n",
    "            x1 = max(int(x1), 0)\n",
    "            y1 = max(int(y1), 0)\n",
    "            w = int(x2) - int(x1)\n",
    "            h = int(y2) - int(y1)\n",
    "            bbox = [x1, y1, w, h]\n",
    "            # Se asigna una etiqueta genérica \"vehicle\"\n",
    "            detections_for_tracker.append((bbox, conf, \"vehicle\"))\n",
    "\n",
    "    # Actualizar el tracker con las detecciones actuales y el frame (opcional para el modelo de features)\n",
    "    tracks = tracker.update_tracks(detections_for_tracker, frame=frame)\n",
    "\n",
    "    # Dibujar bounding boxes y asignar un color único por ID\n",
    "    for track in tracks:\n",
    "        # Solo consideramos tracks confirmados\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "        track_id = track.track_id\n",
    "        l, t, r, b = track.to_ltrb()  # Coordenadas: left, top, right, bottom\n",
    "        color = get_color(track_id)\n",
    "        cv2.rectangle(frame, (int(l), int(t)), (int(r), int(b)), color, 4)\n",
    "        cv2.putText(frame, f'ID: {track_id}', (int(l), int(t)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Guardar el frame procesado en el video de salida\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(\u001b[43mlabels_dir\u001b[49m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels_dir' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import \n",
    "\n",
    "print(os.path.isdir(labels_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
