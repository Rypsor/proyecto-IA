{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video opened. Video properties: Frames per second = 23.976023976023978 | Video size (height x width): 1920 x 1080\n"
     ]
    }
   ],
   "source": [
    "# Before executing this script download the test video from:\n",
    "# https://drive.google.com/file/d/1KD8wfVymKUBqaDVKAdiEM0jh1bQHARn5/view?usp=sharing \n",
    "\n",
    "# Library import\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import models\n",
    "from functions import *\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define and open externally pretrained models\n",
    "#yv8n_model = YOLO(models.yolov8n)\n",
    "yv8n_model = YOLO(\"yolo11n.pt\")\n",
    "lp_model= YOLO(\"models/plate_model.pt\")\n",
    "char_model = YOLO(models.chars3)\n",
    "\n",
    "\n",
    "# Define the path of the video to be analized, load it and print video properties (width, height, frames per second). Raise error if opening is not possible.\n",
    "video_path = 'videos/calle3.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"Video opened. Video properties: Frames per second =\", fps, \"| Video size (height x width):\", height, \"x\", width)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error while opening video.\")\n",
    "    exit()\n",
    "#Defining we are working with a video currently (no stream)\n",
    "stream = False\n",
    "\n",
    "# Determine the vehicle classes that are to be recognized\n",
    "labels = {2:'car',3:'motorcycle',5:'bus',7:'truck'}\n",
    "labels_lp= {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'R', 27: 'S', 28: 'T', 29: 'U', 30: 'V', 31: 'W', 32: 'X', 33: 'Y', 34: 'Z'}\n",
    "\n",
    "# Create an empty list where all the recognized character identifications are going to be stored\n",
    "identified_characters = []\n",
    "\n",
    "\n",
    "# Create image analization loop until the end of the video\n",
    "while True:\n",
    "\n",
    "    # Read the loaded video until the end of the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # Scale frame down to a lower resolution to achieve less necessary computational power and therefore faster vehicle recognition     \n",
    "    new_width = width\n",
    "    new_height = int(height * 9 / 16)\n",
    "    framehd = cv2.resize(frame, (0, 0), fx=1/3, fy=1/3)\n",
    "    frame640 = cv2.resize(framehd, (0, 0), fx=1/2, fy=1/2)\n",
    "    frame320 = cv2.resize(frame640, (0, 0), fx=1/2, fy=1/2)\n",
    "        \n",
    "    # Vehicle detection with loaded YOLOv8n model using the frame with reduced resolution for faster processing | parameter vid_stride defines framerate: every n frames 1 frame is being processed by YOLOv8n\n",
    "    vehicles_results = yv8n_model(frame320, imgsz=320, stream=stream, verbose=False, conf=0.5, classes=[2,3,5,7], vid_stride=2) \n",
    "    \n",
    "    # If no vehicle detection just continue with next iteration\n",
    "    if not vehicles_results: continue\n",
    "    \n",
    "    # Extracting the bounding box coordinates from the results of the vehicle detection model and converting them to a NumPy array of integers\n",
    "    if stream:\n",
    "        vehicles_detected = [result.boxes.cpu().numpy().data.astype(int) for result in vehicles_results][0]\n",
    "    else:\n",
    "        vehicles_results[0].plot()\n",
    "        vehicles_detected = vehicles_results[0].boxes.cpu().data.numpy().astype(int)\n",
    "\n",
    "    # Now pass the coordinate of the bounding boxes of the recognized vehicle to the license plate detecion model.    \n",
    "    for vehicle in vehicles_detected:\n",
    "\n",
    "        # Recovering the 640 pixels image quality for the license plate detection \n",
    "        conf, cls = vehicle[-2:]\n",
    "        r = vehicle[:4] * 2\n",
    "        vehicle_frame = frame640[r[1]:r[3], r[0]:r[2]]\n",
    "    \n",
    "        # Detection of the license plates using the externally pretrained license plate recognition model\n",
    "        lp_results = lp_model(vehicle_frame, imgsz=640, stream=stream, verbose=False, conf=0.5, iou=0.4)\n",
    "        \n",
    "        # If no license plated detected just continue with next iteration\n",
    "        if not lp_results: continue\n",
    "        \n",
    "        # Extracting the bounding box coordinates from the results of the vehicle detection model and converting them to a NumPy array of integers\n",
    "        if stream:\n",
    "            lps_detected = [result.boxes.cpu().numpy().data.astype(int) for result in lp_results][0]\n",
    "        else:\n",
    "            lps_detected = lp_results[0].boxes.cpu().data.numpy().astype(int)\n",
    "            \n",
    "        # Now pass the coordinate of the bounding boxes of the recognized license plate to the character identification model and iterate through them\n",
    "        for lp in lps_detected:\n",
    "            \n",
    "            # Extract from the original frame the license plate detection area and re-establish the original video quality\n",
    "            lp_conf = lp[-2]\n",
    "            rp = lp[:4] * 6\n",
    "            # Pre-selection: sort out all the images where the width-height ratio doesn´t fit the expected license plate ratio\n",
    "            if (rp[2] - rp[0])/(rp[3] - rp[1]) < 1.2 : continue\n",
    "            ro = r*6\n",
    "            lp_frame = frame[ro[1]:ro[3], ro[0]:ro[2]][rp[1]:rp[3], rp[0]:rp[2]]\n",
    "            \n",
    "\n",
    "            # Image pre-processing for better character recognition\n",
    "            # Define where to save the license plate images after preprocessing\n",
    "            subfolder_path = \"fotos\"\n",
    "            current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename_lp = f\"{subfolder_path}/license_plate_{current_time}.png\"\n",
    "            cv2.imwrite(filename_lp, lp_frame)\n",
    "            #Preprocessing way no.1 for yellow license plates\n",
    "            lp_frame_preprocessed_1_step_1 = preprocessing_1_segmentation(lp_frame)\n",
    "            lp_frame_preprocessed_2_step_1 = preprocessing_2_segmentation(lp_frame)\n",
    "            if lp_frame_preprocessed_2_step_1[:,:,2].mean() < 35:\n",
    "                lp_frame_preprocessed_1_step_2 = preprocessing_1_color_correction(lp_frame_preprocessed_1_step_1)\n",
    "                preprocessed_img_3channels = cv2.cvtColor(lp_frame_preprocessed_1_step_2, cv2.COLOR_GRAY2RGB)\n",
    "                #Save preprocessed license plate image 1\n",
    "                filename_ppi_1 = f\"{subfolder_path}/lp_ppi_1_{current_time}.png\"\n",
    "                cv2.imwrite(filename_ppi_1, lp_frame_preprocessed_1_step_2)\n",
    "            else:\n",
    "                #Preprocessing way no.2 for white license plates and converting it into a 3 channel img\n",
    "                lp_frame_preprocessed_2_step_2 = preprocessing_2_color_correction(lp_frame_preprocessed_2_step_1)\n",
    "                preprocessed_img_3channels = cv2.cvtColor(lp_frame_preprocessed_2_step_2, cv2.COLOR_GRAY2RGB)\n",
    "                #Save preprocessed license plate image 2\n",
    "                filename_ppi_2 = f\"{subfolder_path}/lp_ppi_2_{current_time}.png\"\n",
    "                cv2.imwrite(filename_ppi_2, lp_frame_preprocessed_2_step_2)\n",
    "                # print(\"Damaged license plate found.\")\n",
    "                \n",
    "            # Show the preprocessed image\n",
    "            cv2.imshow('Preprocessed license plate',preprocessed_img_3channels)\n",
    "\n",
    "            # Identify the characters on the license plate by the character identification model\n",
    "            char_results = char_model(preprocessed_img_3channels, imgsz=224, stream=stream, verbose=False, iou=0.8, max_det=6, conf=0.2)\n",
    "    \n",
    "            # If no characters detected and identified just continue with next iteration\n",
    "            if not char_results: continue\n",
    "\n",
    "            # Extracting the bounding box coordinates from the results of the character identification model and converting them to a NumPy array of integers\n",
    "            if stream:\n",
    "                chars_detected = [result.boxes.cpu().numpy().data.astype(int) for result in char_results][0]\n",
    "            else:\n",
    "                char_results[0].plot()\n",
    "                chars_detected = char_results[0].boxes.cpu().data.numpy().astype(int)\n",
    "            \n",
    "            # Extract the detected character prediction results if there are 6 characters identified\n",
    "            lp_text = ''\n",
    "            chars_detected_ordenados = sorted(chars_detected, key=lambda char: char[0])\n",
    "            for char in chars_detected_ordenados:\n",
    "                # print(char)\n",
    "                char_conf, char_cls = char[-2:]\n",
    "                rc = char[:4]\n",
    "                # Visualize the identified characters in a green box\n",
    "                cv2.rectangle(lp_frame, rc[:2], rc[2:], (0, 255, 0), 1)\n",
    "                lp_text+=labels_lp[char_cls]\n",
    "            if len(lp_text)==6:\n",
    "                print(lp_text)\n",
    "                # Append the recognized characters to the list identified_characters to save them later on\n",
    "                identified_characters.append(lp_text)\n",
    "            if x:=re.match(re.compile(r'^[A-Z]{3}\\d{2}[A-Z0-9]{1}$'), lp_text):\n",
    "                text = x[0]\n",
    "                print(text)\n",
    "                                \n",
    "            \n",
    "            ###------------Visualization of the detected vehicles, license plates and characters-------------###\n",
    "            # Visualize all the recognized characters\n",
    "            for char in chars_detected:\n",
    "                char_conf = char[-2]\n",
    "                rc = char[:4]\n",
    "                cv2.rectangle(lp_frame, rc[:2], rc[2:], (0, 255, 0), 1)\n",
    "            # Visualize all the recognized license plates \n",
    "            cv2.rectangle(vehicle_frame, lp[:4][:2], lp[:4][2:], (0, 255, 255), 1)\n",
    "            # Use for those recognitions an additional window showing the license plate frame\n",
    "            cv2.imshow('License Plate',lp_frame)\n",
    "\n",
    "        # Visualize the vehicle detection in the 640 pixels frame (adetection of motorcycles in blue, any other vehicle detection in white)\n",
    "        if cls ==3 :\n",
    "            cv2.rectangle(frame640, r[:2], r[2:], (255, 0, 0), 2)\n",
    "        else:\n",
    "            cv2.rectangle(frame640, r[:2], r[2:], (255, 255, 255), 2)\n",
    "\n",
    "    # Show the 640 pixels frame while executing the detection              \n",
    "    cv2.imshow(\"result\", frame640)\n",
    "\n",
    "    # Define options to close the windows and object recognition with the key \"q\" and to pause it with the key \"p\"\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('p'):\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "# Clean finish: Release the captured frame and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the recognized license plates list to a txt-file\n",
    "# Open the file in write mode\n",
    "with open(\"recognitions.txt\", 'w') as file:\n",
    "    # Write each string from the list to the file\n",
    "    for item in identified_characters:\n",
    "        file.write(item + '\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video opened. Video properties: Frames per second = 30.0 | Video size (height x width): 1920 x 1080\n",
      "Guardado imagen de placa: fotos/license_plate_20250315_203442_412401.png\n",
      "Guardada imagen preprocesada (2): fotos/lp_ppi_2_20250315_203442_412401.png\n",
      "Guardado imagen de placa: fotos/license_plate_20250315_203444_468320.png\n",
      "Guardada imagen preprocesada (2): fotos/lp_ppi_2_20250315_203444_468320.png\n",
      "Guardado imagen de placa: fotos/license_plate_20250315_203445_995784.png\n",
      "Guardada imagen preprocesada (2): fotos/lp_ppi_2_20250315_203445_995784.png\n",
      "Guardado imagen de placa: fotos/license_plate_20250315_203448_630273.png\n",
      "Guardada imagen preprocesada (2): fotos/lp_ppi_2_20250315_203448_630273.png\n",
      "Guardado imagen de placa: fotos/license_plate_20250315_203449_862508.png\n",
      "Guardada imagen preprocesada (2): fotos/lp_ppi_2_20250315_203449_862508.png\n",
      "End of video.\n"
     ]
    }
   ],
   "source": [
    "# Before executing this script download the test video from:\n",
    "# https://drive.google.com/file/d/1KD8wfVymKUBqaDVKAdiEM0jh1bQHARn5/view?usp=sharing \n",
    "\n",
    "# Library import\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import models\n",
    "from functions import *\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Create folder to save detected license plate images if it doesn't exist\n",
    "output_folder = \"fotos\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Define and open externally pretrained models\n",
    "# yv8n_model = YOLO(models.yolov8n)\n",
    "yv8n_model = YOLO(\"yolo11n.pt\")\n",
    "lp_model = YOLO(\"models/plate_model.pt\")\n",
    "char_model = YOLO(models.chars3)\n",
    "\n",
    "# Define the path of the video to be analyzed, load it and print video properties\n",
    "video_path = 'videos/calle2.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"Video opened. Video properties: Frames per second =\", fps, \"| Video size (height x width):\", height, \"x\", width)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error while opening video.\")\n",
    "    exit()\n",
    "\n",
    "# We are working with a video (not a stream)\n",
    "stream = False\n",
    "\n",
    "# Define the vehicle classes to be recognized\n",
    "labels = {2: 'car', 3: 'motorcycle', 5: 'bus', 7: 'truck'}\n",
    "labels_lp = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', \n",
    "             10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', \n",
    "             19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'R', 27: 'S', \n",
    "             28: 'T', 29: 'U', 30: 'V', 31: 'W', 32: 'X', 33: 'Y', 34: 'Z'}\n",
    "\n",
    "# Create an empty list where all the recognized character identifications are stored\n",
    "identified_characters = []\n",
    "\n",
    "# Main processing loop: iterate until the end of the video\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # Scale frame down to lower resolution for faster vehicle recognition\n",
    "    new_width = width\n",
    "    new_height = int(height * 9 / 16)\n",
    "    framehd = cv2.resize(frame, (0, 0), fx=1/3, fy=1/3)\n",
    "    frame640 = cv2.resize(framehd, (0, 0), fx=1/2, fy=1/2)\n",
    "    frame320 = cv2.resize(frame640, (0, 0), fx=1/2, fy=1/2)\n",
    "        \n",
    "    # Vehicle detection with YOLO model (processing every 2nd frame for speed)\n",
    "    vehicles_results = yv8n_model(frame320, imgsz=320, stream=stream, verbose=False, conf=0.5, classes=[2,3,5,7], vid_stride=2) \n",
    "    if not vehicles_results: \n",
    "        continue\n",
    "\n",
    "    # Extract bounding boxes from vehicle detection results\n",
    "    if stream:\n",
    "        vehicles_detected = [result.boxes.cpu().numpy().data.astype(int) for result in vehicles_results][0]\n",
    "    else:\n",
    "        vehicles_results[0].plot()\n",
    "        vehicles_detected = vehicles_results[0].boxes.cpu().data.numpy().astype(int)\n",
    "\n",
    "    # Process each detected vehicle for license plate detection\n",
    "    for vehicle in vehicles_detected:\n",
    "        # Recover higher quality image for LP detection\n",
    "        conf, cls = vehicle[-2:]\n",
    "        r = vehicle[:4] * 2\n",
    "        vehicle_frame = frame640[r[1]:r[3], r[0]:r[2]]\n",
    "    \n",
    "        # License plate detection using pretrained model\n",
    "        lp_results = lp_model(vehicle_frame, imgsz=1280, stream=stream, verbose=False, conf=0.5, iou=0.4)\n",
    "        if not lp_results: \n",
    "            continue\n",
    "        \n",
    "        if stream:\n",
    "            lps_detected = [result.boxes.cpu().numpy().data.astype(int) for result in lp_results][0]\n",
    "        else:\n",
    "            lps_detected = lp_results[0].boxes.cpu().data.numpy().astype(int)\n",
    "            \n",
    "        # For each detected license plate, process for character recognition\n",
    "        for lp in lps_detected:\n",
    "            lp_conf = lp[-2]\n",
    "            rp = lp[:4] * 6  # Scale bounding box to original quality\n",
    "            # Pre-selection: discard detections with an unexpected aspect ratio\n",
    "            if (rp[2] - rp[0]) / (rp[3] - rp[1]) < 1.2:\n",
    "                continue\n",
    "            ro = r * 6\n",
    "            lp_frame = frame[ro[1]:ro[3], ro[0]:ro[2]][rp[1]:rp[3], rp[0]:rp[2]]\n",
    "            \n",
    "            # Save the raw detected license plate image in the folder \"fotos\"\n",
    "            current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "            filename_lp = f\"{output_folder}/license_plate_{current_time}.png\"\n",
    "            cv2.imwrite(filename_lp, lp_frame)\n",
    "            print(\"Guardado imagen de placa:\", filename_lp)\n",
    "\n",
    "            # Preprocess image for better character recognition (choose one of the methods)\n",
    "            lp_frame_preprocessed_1_step_1 = preprocessing_1_segmentation(lp_frame)\n",
    "            lp_frame_preprocessed_2_step_1 = preprocessing_2_segmentation(lp_frame)\n",
    "            if lp_frame_preprocessed_2_step_1[:,:,2].mean() < 35:\n",
    "                lp_frame_preprocessed_1_step_2 = preprocessing_1_color_correction(lp_frame_preprocessed_1_step_1)\n",
    "                preprocessed_img_3channels = cv2.cvtColor(lp_frame_preprocessed_1_step_2, cv2.COLOR_GRAY2RGB)\n",
    "                filename_ppi_1 = f\"{output_folder}/lp_ppi_1_{current_time}.png\"\n",
    "                cv2.imwrite(filename_ppi_1, lp_frame_preprocessed_1_step_2)\n",
    "                print(\"Guardada imagen preprocesada (1):\", filename_ppi_1)\n",
    "            else:\n",
    "                lp_frame_preprocessed_2_step_2 = preprocessing_2_color_correction(lp_frame_preprocessed_2_step_1)\n",
    "                preprocessed_img_3channels = cv2.cvtColor(lp_frame_preprocessed_2_step_2, cv2.COLOR_GRAY2RGB)\n",
    "                filename_ppi_2 = f\"{output_folder}/lp_ppi_2_{current_time}.png\"\n",
    "                cv2.imwrite(filename_ppi_2, lp_frame_preprocessed_2_step_2)\n",
    "                print(\"Guardada imagen preprocesada (2):\", filename_ppi_2)\n",
    "            \n",
    "            # (Opcional) Mostrar la imagen preprocesada\n",
    "            cv2.imshow('Preprocessed license plate', preprocessed_img_3channels)\n",
    "\n",
    "            # Identify characters on the license plate (no se guarda el resultado del OCR aquí, solo visualización)\n",
    "            char_results = char_model(preprocessed_img_3channels, imgsz=224, stream=stream, verbose=False, iou=0.8, max_det=6, conf=0.2)\n",
    "            if not char_results: \n",
    "                continue\n",
    "\n",
    "            if stream:\n",
    "                chars_detected = [result.boxes.cpu().numpy().data.astype(int) for result in char_results][0]\n",
    "            else:\n",
    "                char_results[0].plot()\n",
    "                chars_detected = char_results[0].boxes.cpu().data.numpy().astype(int)\n",
    "            \n",
    "            lp_text = ''\n",
    "            chars_detected_ordenados = sorted(chars_detected, key=lambda char: char[0])\n",
    "            for char in chars_detected_ordenados:\n",
    "                char_conf, char_cls = char[-2:]\n",
    "                rc = char[:4]\n",
    "                cv2.rectangle(lp_frame, rc[:2], rc[2:], (0, 255, 0), 1)\n",
    "                lp_text += labels_lp[char_cls]\n",
    "            if len(lp_text) == 6:\n",
    "                print(\"Placa reconocida:\", lp_text)\n",
    "                identified_characters.append(lp_text)\n",
    "            \n",
    "            # Visualización adicional (dibujar sobre el frame)\n",
    "            cv2.rectangle(vehicle_frame, lp[:4][:2], lp[:4][2:], (0, 255, 255), 1)\n",
    "            cv2.imshow('License Plate', lp_frame)\n",
    "\n",
    "        # Visualize vehicle detection on the 640 pixels frame (blue for motorcycles, white for others)\n",
    "        if cls == 3:\n",
    "            cv2.rectangle(frame640, r[:2], r[2:], (255, 0, 0), 2)\n",
    "        else:\n",
    "            cv2.rectangle(frame640, r[:2], r[2:], (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"result\", frame640)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('p'):\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the recognized license plates list to a txt-file\n",
    "with open(\"recognitions.txt\", 'w') as file:\n",
    "    for item in identified_characters:\n",
    "        file.write(item + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: ISEQ - Confianza: 0.47\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "\n",
    "# Crear el objeto lector; puedes especificar los idiomas (en este caso 'en' para inglés)\n",
    "reader = easyocr.Reader(['en'], gpu=False)\n",
    "\n",
    "# Ruta de la imagen (puede ser una imagen de la placa recortada previamente)\n",
    "image_path = \"fotos\\lp_ppi_2_20250315_122540_544457.png\"\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Opcional: Preprocesamiento (por ejemplo, convertir a escala de grises, ajustar contraste, etc.)\n",
    "# img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Leer el texto en la imagen\n",
    "results = reader.readtext(img)\n",
    "\n",
    "# Iterar sobre los resultados para mostrarlos\n",
    "for (bbox, text, confidence) in results:\n",
    "    print(f\"Texto: {text} - Confianza: {confidence:.2f}\")\n",
    "    # Dibujar el rectángulo en la imagen\n",
    "    top_left = tuple(map(int, bbox[0]))\n",
    "    bottom_right = tuple(map(int, bbox[2]))\n",
    "    cv2.rectangle(img, top_left, bottom_right, (0, 255, 0), 2)\n",
    "    # Escribir el texto detectado sobre la imagen\n",
    "    cv2.putText(img, text, top_left, cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "# Mostrar la imagen con las detecciones\n",
    "cv2.imshow(\"OCR EasyOCR\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen: license_plate_20250315_122535_040308.png - Texto: iSE 08) - Confianza: 0.27\n",
      "Imagen: license_plate_20250315_122536_151589.png - Texto: FSE 081 - Confianza: 0.39\n",
      "Imagen: license_plate_20250315_122536_807285.png - Texto: fSE 0&1 - Confianza: 0.13\n",
      "Imagen: license_plate_20250315_122537_665457.png - Texto: FTSE 0g1 - Confianza: 0.08\n",
      "Imagen: license_plate_20250315_122538_385675.png - Texto: fTSE 0g1 - Confianza: 0.28\n",
      "Imagen: license_plate_20250315_122538_736652.png - Texto: FtsE 0g1 - Confianza: 0.04\n",
      "Imagen: license_plate_20250315_122539_273356.png - Texto: TTSE 061 - Confianza: 0.60\n",
      "Imagen: license_plate_20250315_122539_820857.png - Texto: FTSE 081 - Confianza: 0.39\n",
      "Imagen: license_plate_20250315_122540_544457.png - Texto: TTSE 081 - Confianza: 0.34\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import os\n",
    "\n",
    "# Crear el objeto lector para OCR; se especifica el idioma (en este caso, inglés)\n",
    "reader = easyocr.Reader(['en'], gpu=False)\n",
    "\n",
    "# Ruta de la carpeta que contiene las imágenes\n",
    "folder_path = \"fotos\"\n",
    "\n",
    "# Iterar sobre todos los archivos de la carpeta\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Procesar solo archivos de imagen (png, jpg, jpeg)\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"No se pudo leer la imagen {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Aplicar OCR a la imagen\n",
    "        results = reader.readtext(img)\n",
    "\n",
    "        # Dibujar los resultados en la imagen y mostrar información en consola\n",
    "        for (bbox, text, confidence) in results:\n",
    "            print(f\"Imagen: {filename} - Texto: {text} - Confianza: {confidence:.2f}\")\n",
    "            # Convertir las coordenadas a enteros\n",
    "            top_left = tuple(map(int, bbox[0]))\n",
    "            bottom_right = tuple(map(int, bbox[2]))\n",
    "            # Dibujar el rectángulo\n",
    "            cv2.rectangle(img, top_left, bottom_right, (0, 255, 0), 2)\n",
    "            # Escribir el texto sobre la imagen\n",
    "            cv2.putText(img, text, top_left, cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Mostrar la imagen con las detecciones\n",
    "        cv2.imshow(\"OCR EasyOCR\", img)\n",
    "        key = cv2.waitKey(0)  # Espera hasta que se presione una tecla\n",
    "        if key == 27:  # Si se presiona la tecla ESC, salir del bucle\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para la imagen: vehicle_11.jpg\n",
      " No se detectó caption.\n",
      " OCR - Línea: '10577'\n",
      "Resultados para la imagen: vehicle_12.jpg\n",
      " No se detectó caption.\n",
      " No se detectó texto (OCR).\n",
      "Resultados para la imagen: vehicle_13.jpg\n",
      " No se detectó caption.\n",
      " OCR - Línea: 'INO.577'\n",
      "Resultados para la imagen: vehicle_15.jpg\n",
      " No se detectó caption.\n",
      " No se detectó texto (OCR).\n",
      "Resultados para la imagen: vehicle_17.jpg\n",
      " No se detectó caption.\n",
      " No se detectó texto (OCR).\n",
      "Resultados para la imagen: vehicle_18.jpg\n",
      " No se detectó caption.\n",
      " No se detectó texto (OCR).\n",
      "Resultados para la imagen: vehicle_2.jpg\n",
      " No se detectó caption.\n",
      " No se detectó texto (OCR).\n",
      "Resultados para la imagen: vehicle_21.jpg\n",
      " No se detectó caption.\n",
      " No se detectó texto (OCR).\n",
      "Resultados para la imagen: vehicle_24.jpg\n",
      " No se detectó caption.\n",
      " OCR - Línea: 'LIX 570'\n",
      "Resultados para la imagen: vehicle_25.jpg\n",
      " No se detectó caption.\n",
      " OCR - Línea: 'A'\n",
      " OCR - Línea: 'LXX 570'\n",
      "Resultados para la imagen: vehicle_26.jpg\n",
      " No se detectó caption.\n",
      " OCR - Línea: 'LYK 570'\n",
      "Resultados para la imagen: vehicle_3.jpg\n",
      " No se detectó caption.\n",
      " No se detectó texto (OCR).\n",
      "Resultados para la imagen: vehicle_5.jpg\n",
      " No se detectó caption.\n",
      " OCR - Línea: 'CHK-697'\n",
      "Resultados para la imagen: vehicle_7.jpg\n",
      " No se detectó caption.\n",
      " No se detectó texto (OCR).\n",
      "Resultados para la imagen: vehicle_9.jpg\n",
      " No se detectó caption.\n",
      " OCR - Línea: 'ŤSE-061'\n",
      " OCR - Línea: 'MEDELLIN'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import keys\n",
    "\n",
    "# Configuración: Se obtienen las credenciales (endpoint y clave) de tu recurso de Azure\n",
    "endpoint = keys.ocr_endpoint           # Ejemplo: \"https://<tu-recurso>.cognitiveservices.azure.com\"\n",
    "subscription_key = keys.ocr_subscription_key\n",
    "\n",
    "# Crear el cliente de análisis de imágenes de Azure\n",
    "client = ImageAnalysisClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(subscription_key)\n",
    ")\n",
    "\n",
    "# Carpeta que contiene las imágenes locales\n",
    "folder_path = \"detected_vehicles/\"\n",
    "\n",
    "# Recorrer cada archivo de imagen en la carpeta\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        # Leer la imagen con OpenCV (para mostrarla posteriormente con anotaciones)\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"No se pudo leer la imagen {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Abrir la imagen en modo binario y leer sus bytes\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            image_bytes = f.read()\n",
    "\n",
    "        # Llamar al servicio OCR de Azure usando el método analyze (en lugar de analyze_from_url)\n",
    "        # Se solicitan las características CAPTION y READ (OCR)\n",
    "        result = client.analyze(\n",
    "            image_data=image_bytes,\n",
    "            visual_features=[ VisualFeatures.READ, VisualFeatures.OBJECTS],\n",
    "            gender_neutral_caption=True  # Opcional\n",
    "        )\n",
    "\n",
    "        print(f\"Resultados para la imagen: {filename}\")\n",
    "        # Mostrar el caption si existe\n",
    "        if result.caption is not None:\n",
    "            print(f\" Caption: '{result.caption.text}', Confidence {result.caption.confidence:.4f}\")\n",
    "        else:\n",
    "            print(\" No se detectó caption.\")\n",
    "\n",
    "        # Procesar el resultado de OCR (Read)\n",
    "        if result.read is not None and len(result.read.blocks) > 0:\n",
    "            for block in result.read.blocks:\n",
    "                for line in block.lines:\n",
    "                    line_text = \" \".join([word.text for word in line.words])\n",
    "                    print(f\" OCR - Línea: '{line_text}'\")\n",
    "                    # Dibujar los bounding boxes de cada palabra sobre la imagen\n",
    "                    for word in line.words:\n",
    "                        # Se asume que word.bounding_polygon es una lista de puntos con atributos x e y\n",
    "                        pts = [(int(point.x), int(point.y)) for point in word.bounding_polygon]\n",
    "                        pts_np = np.array(pts, np.int32).reshape((-1, 1, 2))\n",
    "                        cv2.polylines(img, [pts_np], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "                        cv2.putText(img, word.text, (pts[0][0], pts[0][1] - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "        else:\n",
    "            print(\" No se detectó texto (OCR).\")\n",
    "\n",
    "        # Mostrar la imagen con las anotaciones\n",
    "        cv2.imshow(\"Azure OCR\", img)\n",
    "        key = cv2.waitKey(0)\n",
    "        if key == 27:  # Si se presiona ESC, salir\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
